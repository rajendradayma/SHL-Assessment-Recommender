# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iil6LfPAEaFS46mhwAHHehCGgYZ3HXYq
"""

 # Corrected the typo in the package name

import pandas as pd
import faiss
import streamlit as st
from sentence_transformers import SentenceTransformer


# SHL Assessment Recommendation Engine using RAG (Retrieval Augmented Generation)
# Streamlit frontend with SentenceTransformer + FAISS backend (Colab-compatible)

import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import os
from pyngrok import ngrok

# === Load and Embed SHL Product Data ===
class SHLRecommender:
    def __init__(self, data_path):
        self.df = pd.read_csv(data_path)
        self.df.fillna("", inplace=True)
        self.texts = (
            self.df['Individual Test Solutions'] + ". " +
            self.df['Description'] + ". " +
            self.df['Job Levels'] + ". " +
            self.df['Test Type']
        ).tolist()

        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.embeddings = self.model.encode(self.texts, show_progress_bar=True)

        self.index = faiss.IndexFlatL2(self.embeddings.shape[1])
        self.index.add(self.embeddings)

    def query(self, user_query, top_k=5):
        query_embedding = self.model.encode([user_query])
        _, indices = self.index.search(query_embedding, top_k)
        results = self.df.iloc[indices[0]].to_dict(orient="records")
        return results

# === Streamlit App File Writing for Colab Compatibility ===
def write_app_file():
    with open("app.py", "w") as f:
        f.write('''
import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss

class SHLRecommender:
    def __init__(self, data_path):
        self.df = pd.read_csv(data_path)
        self.df.fillna("", inplace=True)
        self.texts = (
            self.df['Individual Test Solutions'] + ". " +
            self.df['Description'] + ". " +
            self.df['Job Levels'] + ". " +
            self.df['Test Type']
        ).tolist()

        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.embeddings = self.model.encode(self.texts, show_progress_bar=True)

        self.index = faiss.IndexFlatL2(self.embeddings.shape[1])
        self.index.add(self.embeddings)

    def query(self, user_query, top_k=5):
        query_embedding = self.model.encode([user_query])
        _, indices = self.index.search(query_embedding, top_k)
        results = self.df.iloc[indices[0]].to_dict(orient="records")
        return results

recommender = SHLRecommender("shl_catalog_detailed.csv")

st.set_page_config(page_title="SHL Assessment Recommender", layout="wide")
st.title("üîç SHL Assessment Recommender")

user_query = st.text_input("Enter your job role, skills, or test topic:", "entry level python developer")

if st.button("Recommend Assessments") and user_query:
    with st.spinner("Searching for relevant assessments..."):
        recommendations = recommender.query(user_query)

    st.subheader("üìã Recommended Assessments")
    for rec in recommendations:
        st.markdown(f"**{rec['Individual Test Solutions']}**")
        st.markdown(f"- üîó [Link]({rec['URL']})")
        st.markdown(f"- üìÑ Description: {rec['Description']}")
        st.markdown(f"- üíº Job Levels: {rec['Job Levels']}")
        st.markdown(f"- üß™ Test Type: {rec['Test Type']}")
        st.markdown("---")
''')

# === Setup ngrok tunnel and run Streamlit App ===
def launch_streamlit():
    write_app_file()
    from pyngrok import conf
    conf.get_default().auth_token = "2uoo6zGCOe7cYc2sYAtcrKSTUzO_3iT9iR82wD4N1TSY6GXE9"  # üëà paste your token here

    ngrok.kill()
    public_url = ngrok.connect(8501)
    print("\nüåê Streamlit app is live at:", public_url)
    os.system("streamlit run app.py &")

launch_streamlit()





